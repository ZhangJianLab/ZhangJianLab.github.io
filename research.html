---
layout: page
title: 学术论文与发表论文
permalink: /research/
---

<font size="+2"><strong> 代表性论文</strong></font><br>
<strong><a href="https://schlr.cnki.net/zn/Detail/index/journal/SJHDD0DAA93E61A828351F1FC2E3180DD769"> Embedded YOLO: A Real-Time Object Detector for Small Intelligent Trajectory Cars</a></strong><i>, 冯文宇等, Mathematical Problems in Engineering</i>, 2021<br>
<p style="text-align:justify"><b><i>Abstract: </i></b>YOLO-Tiny is a lightweight version of the object detection model based on the original “You only look once” (YOLO) model for simplifying network structure and reducing parameters, which makes it suitable for real-time applications. Although the YOLO-Tiny series, which includes YOLOv3-Tiny and YOLOv4-Tiny, can achieve real-time performance on a powerful GPU, it remains challenging to leverage this approach for real-time object detection on embedded computing devices, such as those in small intelligent trajectory cars. To obtain real-time and high-accuracy performance on these embedded devices, a novel object detection lightweight network called embedded YOLO is proposed in this paper. First, a new backbone network structure, ASU-SPP network, is proposed to enhance the effectiveness of low-level features. Then, we designed a simplified version of the neck network module PANet-Tiny that reduces computation complexity. Finally, in the detection head module, we use depthwise separable convolution to reduce the number of convolution stacks. In addition, the number of channels is reduced to 96 dimensions so that the module can attain the parallel acceleration of most inference frameworks. With its lightweight design, the proposed embedded YOLO model has only 3.53M parameters, and the average processing time can reach 155.1 frames per second, as verified by Baidu smart car target detection. At the same time, compared with YOLOv3-Tiny and YOLOv4-Tiny, the detection accuracy is 6% higher.</p>
<br>
<strong><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2020&filename=YQXB202008021&uniplatform=NZKPT&v=gotsSDAvdJ7bn36mFplniBKLDtRcS4T3eRDW0QUCPdoDNOaYSbL88zt4JtrFskpy"> 无人CT智能姿态识别算法研究</a></strong><i>, 冯文宇、殷佳炜等，仪器仪表学报</i>, 2020<br>
<p style="text-align:justify"><b><i>摘要: </i></b>针对新冠肺炎疫情中肺部CT检查需要医生人工指导矫正姿态和交叉感染风险大的问题,提出基于人体姿态识别的无人CT智能姿态识别算法。通过CT-OpenPose模型检测人体姿势,该算法在OpenPose模型基础上,解决了传统模型硬件性能要求高、检测速度慢和复杂环境下检测精度下降等问题,使用带自适应软阈值残差网络、跨层连接机制和权值修剪的方法对传统模型在底层特征提取方式、底层特征处理流程、模型训练和压缩方面进行改进。实验结果表明,在无人CT姿态识别任务中,CT-OpenPose模型检测精度高于传统模型,为83.6%,尤其在人体关键部位被臃肿的衣物或防护衣物遮挡的情况下,检测速度是传统模型的近3倍,达到42.2 f/s,具备较高的实用性。</p>
<br>
<strong><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2022&filename=JYXH202112005&uniplatform=NZKPT&v=y1kdKYHGttllcKHpsFA3GL7_Bzks3LoenusADT1hpSR5fQkZkfCK8wB2IaG5_dFQ"> 基于通道切分的人体姿态估计算法</a></strong><i>, 周昆阳等，计算机与现代化</i>, 2021<br>
<p style="text-align:justify"><b><i>摘要: </i></b>为了提高人体姿态估计的准确率和识别速度,提出一种基于通道切分的人体姿态估计算法Channel-Split Residual Steps Network（Channel-Split RSN）。首先,提出通道切分模块,对切分后的特征通道通过卷积提取特征再融合起来,以获得丰富的特征表示。接着,引入特征增强模块,对特征通道进一步分组,并对不同的分组采取不同的处理策略,以减少特征通道内的相似特征。最后,结合改进的空间注意力机制,提出一种基于特征空间相关性的姿态修正机Context-PRM,得到更加准确的人体姿态估计。在COCO test-dev数据集上的实验结果表明,本文方法达到75.9%的AP和55.36的FPS,并且模型的大小Params（M）仅为18.3。相较于传统的RSN18和传统的RSN50,模型的AP分别提高了5和3.4个百分点,FPS比传统的RSN50快12.08。在更具挑战性的CrowdPose数据集上,本文方法达到66.9%的AP和19.16的FPS,相较于RSN18,AP提高了4.6个百分点。有效提高了人体姿态估计的准确率,且模型具有较快的识别速度。本文源代码公开在https://github. com/qdd1234/Channel-Split-RSN。</p>
<br>
<strong><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=DZIY202106006&uniplatform=NZKPT&v=Wv0d6jpa-1l2BQbxZkozCzXWqhZS3NXr5dX-nFETU3jOtxqiYwqTZUgM8VXFm8M2"> 复杂环境下课堂多人状态检测算法研究</a></strong><i>, 冯文宇等，电子测量与仪器学报</i>, 2021<br> 
<p style="text-align:justify"><b><i>摘要: </i></b>新冠肺炎疫情背景下课堂多人佩戴口罩及姿态识别问题,提出了基于YOLO和OpenPose模型的课堂多人状态检测算法。提出的Efficient-YOLO模型,通过采用CBAM注意力模块、SPNET-NEW模块,解决了多人遮挡和无规则化目标的口罩佩戴检测精度问题。此外,提出了一种轻量化的Class-OpenPose模型检测学生上课姿态,该算法在OpenPose模型基础上,使用ShuffleNetV2-NEW对传统模型在底层特征提取方面进行改进,实现了复杂环境下关键姿态点的实时准确检测。实验表明,在课堂多人异常状态检测任务中,Class-OpenPose模型平均准确率高于传统模型,为79.0%,检测速度达到13.5 F/s; Efficient-YOLO口罩识别模型达到83.1%的平均准确率,检测时间仅需31.54 ms,为课堂学生状态检测提供了不错的算法思路。</p>
<br>

<font size="+2"><strong> 代表性发明专利</strong></font><br>
<strong>一种基于改进半监督学习的电瓶车头盔识别方法</strong><br>周昆阳等，CN202210426001.7;<br>
<strong>一种交通信号灯倒计时识别系统及其构建方法、应用方法</strong><br>周昆阳等，CN202111160244.2;<br>
<strong>一种基于改进轻量级YOLOv3的交通信号灯倒计时识别方法</strong><br>周昆阳、杨启硕等，CN202110599256.9;<br>
<strong>一种可升降式多功能智能鞋柜</strong><br>李昀迪，刘鑫慧等，CN202110666986.6;<br>
<strong>一种基于人工智能的导盲机器狗</strong><br>李昀迪等，CN202110274036.9;<br>
<strong>一种基于ToF技术的多场景小型自动焊接机器人</strong><br>张帆等，CN202210260652.3<br>
<strong>一种基于Kolmogorov-Smirnov检验的微小故障检测方法</strong><br>张帆等，CN202210155043.1<br>
